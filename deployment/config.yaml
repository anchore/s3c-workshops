# Anchore Enterprise default configuration file bundled into the container. These values should provide a simple starting point
# To fully customize configuration, provide a different config.yaml to container at startup by mounting a directory
# at /config that has the config.yaml


# These defaults are intended to serve a deployment where each service is started in its own container with individual overrides
# for values like the endpoint hostname. This config provides a uniform setting of those such that env vars passed in from
# execution will overwrite values needed.

service_dir: ${ANCHORE_SERVICE_DIR}
tmp_dir: /analysis_scratch
log_level: ${ANCHORE_LOG_LEVEL}

# When set, if a registry credential username is set to 'iamauto' for an ecr registry, the engine will
# use whatever aws creds are available in the standard boto search path (.aws, env, etc)
allow_awsecr_iam_auto: true
host_id: "${ANCHORE_HOST_ID}"
internal_ssl_verify: ${ANCHORE_INTERNAL_SSL_VERIFY}

global_client_connect_timeout: ${ANCHORE_GLOBAL_CLIENT_CONNECT_TIMEOUT}
global_client_read_timeout: ${ANCHORE_GLOBAL_CLIENT_READ_TIMEOUT}

# Twisted has a global server side timeout on all established connections which defaults to 60, anything lasting longer
# than this (+ a 15 min abort final timeout) will have the connection killed by twisted
server_request_timeout_seconds: ${ANCHORE_GLOBAL_SERVER_REQUEST_TIMEOUT_SEC}

auto_restart_services: false

# Defines a maximum compressed image size (MB) to be added for analysis
# Value < 0 disables feature
# Disabled by default
max_compressed_image_size_mb: ${ANCHORE_MAX_COMPRESSED_IMAGE_SIZE_MB}

# Defines the maximum source repository sbom size (in MB) allowed to be imported
max_source_import_size_mb: ${ANCHORE_MAX_IMPORT_SOURCE_SIZE_MB}

# Defines the maximum sbom size (in MB) allowed to be imported
max_import_content_size_mb: ${ANCHORE_MAX_IMPORT_CONTENT_SIZE_MB}

# Locations for keys used for signing and encryption. Only one of 'secret' or 'public_key_path'/'private_key_path' needs to be set. If all are set then the keys take precedence over the secret value
# Secret is for a shared secret and if set, all components in anchore should have the exact same value in their configs.
#
keys:
  secret: ${ANCHORE_AUTH_SECRET}
  public_key_path: ${ANCHORE_AUTH_PUBKEY}
  private_key_path: ${ANCHORE_AUTH_PRIVKEY}

# Configuring supported user authentication and credential management
user_authentication:
  oauth:
    enabled: ${ANCHORE_OAUTH_ENABLED}
    default_token_expiration_seconds: ${ANCHORE_OAUTH_TOKEN_EXPIRATION}
    refresh_token_expiration_seconds: ${ANCHORE_OAUTH_REFRESH_TOKEN_EXPIRATION}

  # Set this to True to enable storing user passwords only as secure hashes in the db. This can dramatically increase CPU usage if you
  # don't also use oauth and tokens for internal communications (which requires keys/secret to be configured as well)
  # WARNING: you should not change this after a system has been initialized as it may cause a mismatch in existing passwords
  hashed_passwords: ${ANCHORE_AUTH_ENABLE_HASHED_PASSWORDS}

  # Set this to True in order to disable the SSO JIT provisioning during authentication. This provides an additional
  # layer of security and configuration for SSO users to gain access to Anchore.  This is disabled by default.
  sso_require_existing_users: ${ANCHORE_SSO_REQUIRES_EXISTING_USERS}

  # Set this to True to enable API key generation and authentication for SAML users. This is disabled by default.
  # NOTE: Enterprise cannot automatically revoke or delete keys for disabled SAML users, the onus is on the user/admin
  #       to revoke all keys assigned to a SAML user after disabling them.
  allow_api_keys_for_saml_users: false

  # The number of days that API keys are valid for before they must be regenerated. Defaults to 365 days.
  max_api_key_age_days: 365

  # The number of API keys each user is allowed to have. Defaults to 100.
  # This includes Active, Expired and Revoked keys.
  max_api_keys_per_user: 100

  # The number of days elapsed after a user API key is deleted before it is garbage collected (-1 to disable)
  remove_deleted_user_api_keys_older_than_days: -1

license_file: ${ANCHORE_ENTERPRISE_LICENSE_PATH}


metrics:
  enabled: ${ANCHORE_ENABLE_METRICS}
  auth_disabled: ${ANCHORE_DISABLE_METRICS_AUTH}

# Uncomment if you have a local endpoint that can accept
# notifications from the anchore-engine, as configured below
# This section is only required on the catalog service containers
webhooks:
  webhook_user: null
  webhook_pass: null
  ssl_verify: false
  general:
    url: ${ANCHORE_WEBHOOK_DESTINATION_URL}
  policy_eval: { }
  event_log: { }

# As of 0.3.0 this section is used instead of the credentials.users section
# Can be omitted and will default to 'foobar' on db initialization
default_admin_password: ${ANCHORE_ADMIN_PASSWORD}

# Can be omitted and will default to 'admin@myanchore'
default_admin_email: ${ANCHORE_ADMIN_EMAIL}

credentials:
  database:
    # New connection format as individual components
    user: ${ANCHORE_DB_USER} # Required
    password: ${ANCHORE_DB_PASSWORD} # Optional
    host: ${ANCHORE_DB_HOST} # Required
    port: ${ANCHORE_DB_PORT} # Optional, defaults to 5432
    name: ${ANCHORE_DB_NAME} # Required

    # Legacy connection string format
    # db_connect: 'postgresql://${ANCHORE_DB_USER}:${ANCHORE_DB_PASSWORD}@${ANCHORE_DB_HOST}:${ANCHORE_DB_PORT}/${ANCHORE_DB_NAME}'

    db_connect_args:
      timeout: 120
      ssl: false
    db_pool_size: 30
    db_pool_max_overflow: 100
services:
  apiext:
    enabled: true
    require_auth: true
    endpoint_hostname: '${ANCHORE_ENDPOINT_HOSTNAME}'
    listen: '0.0.0.0'
    port: ${ANCHORE_SERVICE_PORT}
    authorization_handler: external
    authorization_handler_config:
      endpoint: ${ANCHORE_EXTERNAL_AUTHZ_ENDPOINT}
  catalog:
    enabled: true
    require_auth: true
    endpoint_hostname: '${ANCHORE_ENDPOINT_HOSTNAME}'
    listen: '0.0.0.0'
    port: ${ANCHORE_SERVICE_PORT}
    # NOTE: use the below external_* parameters to define the port/tls
    # setting that will allow other internal services to access this
    # service - if left unset services will use the above,
    # e.g. http://<endpoint_hostname>:<port>
    external_port: ${ANCHORE_EXTERNAL_PORT}
    external_tls: ${ANCHORE_EXTERNAL_TLS}
    object_store:
      verify_content_digests: true # Ensures the data read for the object store has the same digest as what was written. This defaults to true if unset. Set to false ONLY for debugging and other special cases.
      compression:
        enabled: false
        min_size_kbytes: 100
      storage_driver:
        name: db
        config:
    # The analysis archive will default to use the same storage driver as the object storage, uncomment here to use a different configuration
    #    analysis_archive:
    #      check_content_digests: true
    #      compression:
    #        enabled: false
    #        min_size_kbytes: 100
    #      storage_driver:
    #        name: db
    #        config: { }
    cycle_timer_seconds: 1
    cycle_timers:
      image_watcher: 3600
      policy_eval: 3600
      vulnerability_scan: 14400
      analyzer_queue: 1
      notifications: ${ANCHORE_CATALOG_NOTIFICATION_INTERVAL_SEC}
      service_watcher: 15
      policy_bundle_sync: 300
      repo_watcher: 60
      archive_tasks: 43200 # 12 hours between archive task run
      image_gc: ${ANCHORE_CATALOG_IMAGE_GC_INTERVAL_SEC}
      k8s_image_watcher: ${ANCHORE_CATALOG_K8S_INVENTORY_WATCH_IMAGE_INTERVAL_SEC} # 2.5 minutes between image watch polls, by default
      resource_metrics: 60
      events_gc: 43200 # 12 hours
      artifact_lifecycle_policy_tasks: 43200,  # 12 hours
    event_log:
      # Events older than this number of days are automatically deleted from the system to keep db usage predictable. Set to 0 to disable cleanup (default).
      max_retention_age_days: ${ANCHORE_EVENT_RETENTION_AGE_DAYS}
      notification:
        enabled: ${ANCHORE_EVENTS_NOTIFICATIONS_ENABLED}
        # (optional) notify events that match these levels. If this section is commented, notifications for all events are sent
        level:
          - error
    runtime_inventory:
      # This setting tells Anchore how long an image can be missing from an inventory report before it is removed from
      # The working set. Note: The image will still have a historical record in the reports service, subject to data history
      # constraints as part of that service.
      inventory_ttl_days: ${ANCHORE_ENTERPRISE_RUNTIME_INVENTORY_TTL_DAYS}
      inventory_ingest_overwrite: false

    image_gc:
      max_worker_threads: ${ANCHORE_CATALOG_IMAGE_GC_WORKERS}
    runtime_compliance:
      object_store_bucket: "runtime_compliance_check"
    down_analyzer_task_requeue: true
    import_operation_expiration_days: 7
  simplequeue:
    enabled: true
    require_auth: true
    endpoint_hostname: '${ANCHORE_ENDPOINT_HOSTNAME}'
    listen: '0.0.0.0'
    port: ${ANCHORE_SERVICE_PORT}
    external_port: ${ANCHORE_EXTERNAL_PORT}
    external_tls: ${ANCHORE_EXTERNAL_TLS}
  analyzer:
    enabled: true
    require_auth: true
    cycle_timer_seconds: 1
    cycle_timers:
      image_analyzer: 1
    analyzer_driver: 'nodocker'
    endpoint_hostname: '${ANCHORE_ENDPOINT_HOSTNAME}'
    listen: '0.0.0.0'
    port: ${ANCHORE_SERVICE_PORT}
    external_port: ${ANCHORE_EXTERNAL_PORT}
    external_tls: ${ANCHORE_EXTERNAL_TLS}
    layer_cache_enabled: ${ANCHORE_LAYER_CACHE_ENABLED}
    layer_cache_max_gigabytes: ${ANCHORE_LAYER_CACHE_SIZE_GB}
    enable_hints: ${ANCHORE_HINTS_ENABLED}
    keep_image_analysis_tmpfiles: false
  policy_engine:
    enabled: true
    require_auth: true
    endpoint_hostname: '${ANCHORE_ENDPOINT_HOSTNAME}'
    listen: '0.0.0.0'
    port: ${ANCHORE_SERVICE_PORT}
    external_port: ${ANCHORE_EXTERNAL_PORT}
    external_tls: ${ANCHORE_EXTERNAL_TLS}
    policy_evaluation_cache_ttl: ${ANCHORE_POLICY_EVAL_CACHE_TTL_SECONDS} # 1 hour for policy eval results to expire. Should generally never need to be modified
    cycle_timer_seconds: 1
    cycle_timers:
      feed_sync: ${ANCHORE_FEED_SYNC_INTERVAL_SEC} # 6 hours between feed syncs
      feed_sync_checker: 3600 # 1 hour between checks to see if there needs to be a task queued
    enable_package_db_load: ${ANCHORE_POLICY_ENGINE_ENABLE_PACKAGE_DB_LOAD} # Controls the load of the Image Package DB Entries and disables the packages.verify gate. Reduces significant DB load as a result. Defaults to true if not set
    vulnerabilities:
      sync:
        enabled: ${ANCHORE_FEEDS_ENABLED}
        ssl_verify: ${ANCHORE_FEEDS_SSL_VERIFY}
        connection_timeout_seconds: 3
        read_timeout_seconds: 60
        data:
          # grypedb feed is synced if the provider is set to grype. All the remaining feeds except for packages are ignored even if they are enabled
          grypedb:
            enabled: true
            url: ${ANCHORE_GRYPE_DB_URL}
          # Warning: enabling the packages and nvd sync causes the service to require much
          #   more memory to do process the significant data volume. We recommend at least 4GB available for the container
          # packages feed is synced if it is enabled regardless of the provider
          #packages:
          #  enabled: true
          #  url: ${ANCHORE_FEEDS_URL}
      matching:
        default:
          search:
            by_cpe:
              enabled: ${ANCHORE_VULN_MATCHING_DEFAULT_SEARCH_BY_CPE_ENABLED}
        ecosystem_specific:
          dotnet:
            search:
              by_cpe:
                enabled: ${ANCHORE_VULN_MATCHING_ECOSYSTEM_SPECIFIC_DOTNET_SEARCH_BY_CPE_ENABLED}
          golang:
            search:
              by_cpe:
                enabled: ${ANCHORE_VULN_MATCHING_ECOSYSTEM_SPECIFIC_GOLANG_SEARCH_BY_CPE_ENABLED}
          java:
            search:
              by_cpe:
                enabled: ${ANCHORE_VULN_MATCHING_ECOSYSTEM_SPECIFIC_JAVA_SEARCH_BY_CPE_ENABLED}
          javascript:
            search:
              by_cpe:
                enabled: ${ANCHORE_VULN_MATCHING_ECOSYSTEM_SPECIFIC_JAVASCRIPT_SEARCH_BY_CPE_ENABLED}
          python:
            search:
              by_cpe:
                enabled: ${ANCHORE_VULN_MATCHING_ECOSYSTEM_SPECIFIC_PYTHON_SEARCH_BY_CPE_ENABLED}
          ruby:
            search:
              by_cpe:
                enabled: ${ANCHORE_VULN_MATCHING_ECOSYSTEM_SPECIFIC_RUBY_SEARCH_BY_CPE_ENABLED}
          stock:
            search:
              by_cpe:
                # Disabling search by CPE for the stock matcher will entirely disable binary-only matches
                # and is not advised
                enabled: ${ANCHORE_VULN_MATCHING_ECOSYSTEM_SPECIFIC_STOCK_SEARCH_BY_CPE_ENABLED}

  # This should never be exposed outside of linked containers/localhost. It is used only for internal service access
  rbac_authorizer:
    enabled: true
    require_auth: true
    endpoint_hostname: "${ANCHORE_ENDPOINT_HOSTNAME}"
    # Normally this would be 127.0.0.1, but for docker compose have to bind to other for routing
    listen: '0.0.0.0'
    port: 8228
  rbac_manager:
    enabled: true
    require_auth: true
    endpoint_hostname: "${ANCHORE_ENDPOINT_HOSTNAME}"
    listen: '0.0.0.0'
    port: 8228
    authorization_handler: external
    authorization_handler_config:
      endpoint: "${ANCHORE_EXTERNAL_AUTHZ_ENDPOINT}"
  feeds:
    enabled: true
    require_auth: false
    endpoint_hostname: "${ANCHORE_ENDPOINT_HOSTNAME}"
    listen: '0.0.0.0'
    port: 8228
    cycle_timers:
      # Time delay in seconds between consecutive driver runs for processing data
      driver_sync: 7200
    # Staging space for holding normalized output from drivers. Persisted using a volume defined in docker-compose
    local_workspace: '/workspace'
    # Drivers process data from external sources and store normalized data in local_workspace. Processing large data sets
    # is a time consuming process for some drivers. To speed it up the container is shipped with pre-loaded data that is used
    # by default if local_workspace is empty
    workspace_preload:
      # Set enabled to false to force drivers to generate normalized data from scratch if local_workspace is empty
      enabled: true
      workspace_preload_file: '/workspace_preload/data.tar.gz'
    # Set api_only to true for operating the service in read-only mode. API end points will and serve persisted data but all drivers will be disabled
    api_only: "${ANCHORE_ENTERPRISE_API_ONLY}"
    drivers:
      # Configuration section for drivers gathering and normalizing feed data.
      amzn:
        enabled: true
      alpine:
        enabled: true
      debian:
        enabled: true
      ol:
        enabled: true
      ubuntu:
        enabled: true
      rhel:
        enabled: true
        concurrency: 5
      npm:
        # npm driver is disabled out of the box
        enabled: "${ANCHORE_ENTERPRISE_PACKAGE_DRIVERS_ENABLED}"
      gem:
        # rubygems driver is disabled out of the box
        enabled: "${ANCHORE_ENTERPRISE_PACKAGE_DRIVERS_ENABLED}"
        # rubygems package data is a PostgreSQL dump. db_connect string defines the database endpoint to be used for loading the data
        db_connect: 'postgresql://${ANCHORE_DB_USER}:${ANCHORE_DB_PASSWORD}@${ANCHORE_DB_HOST}:${ANCHORE_DB_PORT}/${ANCHORE_RUBYGEMS_DB_NAME}'
      nvdv2:
        enabled: true
        # An API key is optional but is recommended to reduce rate limiting. Request one from https://nvd.nist.gov/developers/request-an-api-key
        api_key: "${ANCHORE_ENTERPRISE_FEEDS_NVD_PROVIDER_API_KEY}"
      mariner:
        enabled: true
      msrc:
        enabled: "${ANCHORE_ENTERPRISE_FEEDS_MSRC_DRIVER_ENABLED}"
        # Uncomment to add MSRC product IDs for generating their feed data, this extends the pre-defined list of product IDs
        # whitelist:
        # - 12345
      github:
        enabled: true
        token: "${ANCHORE_ENTERPRISE_FEEDS_GITHUB_DRIVER_TOKEN}"
      grypedb:
        enabled: true
        preload:
          enabled: true
          workspace_archive_path: "/preload/grype-db-workspace.tar.gz"
        persist_provider_workspaces: true
        restore_provider_workspaces: true
      sles:
        enabled: true
      anchore_match_exclusions:
        enabled: "${ANCHORE_ENTERPRISE_FEEDS_VULN_MATCH_EXCLUSION_DRIVER_ENABLED}"
      wolfi:
        enabled: true
      chainguard:
        enabled: true
  reports:
    enabled: true
    require_auth: true
    endpoint_hostname: "${ANCHORE_ENDPOINT_HOSTNAME}"
    listen: '0.0.0.0'
    port: 8228
    # GraphiQL is a GUI for editing and testing GraphQL queries and mutations.
    # Set enable_graphiql to true and open http://<host>:<port>/v2/reports/graphql in a browser for reports API
    enable_graphiql: "${ANCHORE_ENTERPRISE_REPORTS_ENABLE_GRAPHQIQL}"
    authorization_handler: external
    authorization_handler_config:
      endpoint: "${ANCHORE_EXTERNAL_AUTHZ_ENDPOINT}"
    cycle_timers:
      reports_scheduled_queries: 600 # 10 Minutes - Check for scheduled queries that need to be run
    # Configure max_async_execution_threads to adjust how many scheduled reports to generate in parallel
    max_async_execution_threads: 1
    # Configure async_execution_timeout to adjust how long a scheduled query must be running for before it is considered timed out
    # This may need to be adjusted if the system has large amounts of data and reports are being prematurely timed out.
    # The value should be a number followed by "w", "d", or "h" to represent weeks, days or hours
    async_execution_timeout: "48h"
    # Set use_volume to `true` to have the reports worker buffer report generation to disk instead of in memory. This should be configured
    # in production systems with large amounts of data (10s of thousands of images or more). Scratch volumes should be configured for the reports pods
    # when this option is enabled.
    use_volume: false
  reports_worker:
    enabled: true
    require_auth: true
    endpoint_hostname: "${ANCHORE_ENDPOINT_HOSTNAME}"
    listen: '0.0.0.0'
    port: 8228
    # Set enable_data_ingress to true for periodically syncing data from anchore enterprise into the reports service
    enable_data_ingress: ${ANCHORE_ENTERPRISE_REPORTS_ENABLE_DATA_INGRESS}
    # Set enable_data_egress to true to periodically remove reporting data that has been removed in other parts of system
    enable_data_egress: ${ANCHORE_ENTERPRISE_REPORTS_ENABLE_DATA_EGRESS}
    # data_egress_window defines a number of days to keep reporting data following its deletion in the rest of system.
    # Default value of 0 will remove it on next task run
    data_egress_window: ${ANCHORE_ENTERPRISE_REPORTS_DATA_EGRESS_WINDOW}
    # data_refresh_max_workers is the maximum number of concurrent threads to refresh existing results (etl vulnerabilities and evaluations) in reports service. Set non-negative values greater than 0, otherwise defaults to 10
    data_refresh_max_workers: 10
    # data_load_max_workers is the maximum number of concurrent threads to load new results (etl vulnerabilities and evaluations) to reports service. Set non-negative values greater than 0, otherwise defaults to 10
    data_load_max_workers: 10
    cycle_timers:
      reports_image_load: ${ANCHORE_ENTERPRISE_REPORTS_DATA_LOAD_INTERVAL_SEC}  # MIN 300 MAX 100000 Default 600
      reports_tag_load: ${ANCHORE_ENTERPRISE_REPORTS_DATA_LOAD_INTERVAL_SEC}  # MIN 300 MAX 100000 Default 600
      reports_runtime_inventory_load: ${ANCHORE_ENTERPRISE_REPORTS_DATA_LOAD_INTERVAL_SEC}  # MIN 300 MAX 100000 Default 600
      reports_extended_runtime_vuln_load: ${ANCHORE_ENTERPRISE_REPORTS_RUNTIME_INV_DATA_LOAD_INTERVAL_SEC}  # MIN 300 MAX 100000 Default 1800
      reports_image_refresh: ${ANCHORE_ENTERPRISE_REPORTS_DATA_REFRESH_INTERVAL_SEC}  # MIN 3600 MAX 100000 Default 7200
      reports_tag_refresh: ${ANCHORE_ENTERPRISE_REPORTS_DATA_REFRESH_INTERVAL_SEC}  # MIN 3600 MAX 100000 Default 7200
      reports_metrics: ${ANCHORE_ENTERPRISE_REPORTS_METRICS_INTERVAL_SEC}  # MIN 1800 MAX 100000 Default 3600
      reports_image_egress: ${ANCHORE_ENTERPRISE_REPORTS_DATA_EGRESS_INTERVAL_SEC}  # MIN 300 MAX 100000 Default 600
      reports_tag_egress: ${ANCHORE_ENTERPRISE_REPORTS_DATA_EGRESS_INTERVAL_SEC}  # MIN 300 MAX 100000 Default 600
    runtime_report_generation:
      inventory_images_by_vulnerability: true
      vulnerabilities_by_k8s_namespace: ${ANCHORE_ENTERPRISE_REPORTS_GENERATE_VULN_K8S_NAMESPACE}
      vulnerabilities_by_k8s_container: ${ANCHORE_ENTERPRISE_REPORTS_GENERATE_VULN_K8S_CONTAINER}
      vulnerabilities_by_ecs_container: ${ANCHORE_ENTERPRISE_REPORTS_GENERATE_VULN_ECS_CONTAINER}
  notifications:
    enabled: true
    require_auth: true
    endpoint_hostname: "${ANCHORE_ENDPOINT_HOSTNAME}"
    listen: '0.0.0.0'
    port: 8228
    authorization_handler: external
    authorization_handler_config:
      endpoint: "${ANCHORE_EXTERNAL_AUTHZ_ENDPOINT}"
    cycle_timers:
      notifications: 30
    # Set Anchore Enterprise UI base:v1.0.0 URL to receive UI links in notifications
    ui_url: "${ANCHORE_ENTERPRISE_UI_URL}"